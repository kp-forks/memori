---
title: OpenAI
description: Using Memori with OpenAI models including GPT-4o, GPT-4.1, and the Responses API with Memori BYODB.
---

# OpenAI

Memori supports all OpenAI models and API styles. Register your client once and every call is automatically captured and stored.

<Note>
  Want a zero-setup option? The Memori Cloud at
  [app.memorilabs.ai](https://app.memorilabs.ai).
</Note>

## Quick Start

<CodeGroup title="OpenAI Integration">

```python {{ title: 'Sync' }}
from memori import Memori
from openai import OpenAI
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

engine = create_engine("sqlite:///memori.db")
SessionLocal = sessionmaker(bind=engine)

client = OpenAI()
mem = Memori(conn=SessionLocal).llm.register(client)
mem.config.storage.build()
mem.attribution(entity_id="user_123", process_id="my_agent")

response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "Hello!"}]
)
print(response.choices[0].message.content)
```

```python {{ title: 'Async' }}
import asyncio
from memori import Memori
from openai import AsyncOpenAI
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

engine = create_engine("sqlite:///memori.db")
SessionLocal = sessionmaker(bind=engine)

client = AsyncOpenAI()
mem = Memori(conn=SessionLocal).llm.register(client)
mem.config.storage.build()
mem.attribution(entity_id="user_123", process_id="my_agent")

async def main():
    response = await client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": "Hello!"}]
    )
    print(response.choices[0].message.content)

asyncio.run(main())
```

```python {{ title: 'Streaming' }}
from memori import Memori
from openai import OpenAI
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

engine = create_engine("sqlite:///memori.db")
SessionLocal = sessionmaker(bind=engine)

client = OpenAI()
mem = Memori(conn=SessionLocal).llm.register(client)
mem.config.storage.build()
mem.attribution(entity_id="user_123", process_id="my_agent")

stream = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "Hello!"}],
    stream=True
)
for chunk in stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="")
```

```python {{ title: 'Responses API' }}
from memori import Memori
from openai import OpenAI
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

engine = create_engine("sqlite:///memori.db")
SessionLocal = sessionmaker(bind=engine)

client = OpenAI()
mem = Memori(conn=SessionLocal).llm.register(client)
mem.config.storage.build()
mem.attribution(entity_id="user_123", process_id="my_agent")

response = client.responses.create(
    model="gpt-4o-mini",
    input="Hello!",
    instructions="You are a helpful assistant."
)
print(response.output_text)
```

</CodeGroup>

## Supported Modes

| Mode              | Method                                   |
| ----------------- | ---------------------------------------- |
| **Sync**          | `client.chat.completions.create()`       |
| **Async**         | `await client.chat.completions.create()` |
| **Streamed**      | `stream=True` parameter                  |
| **Responses API** | `client.responses.create()`              |

## Multi-Turn Conversations

Memori captures each call and links them within the same session. Pass your full conversation history as usual.

```python
from memori import Memori
from openai import OpenAI
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

engine = create_engine("sqlite:///memori.db")
SessionLocal = sessionmaker(bind=engine)

client = OpenAI()
mem = Memori(conn=SessionLocal).llm.register(client)
mem.attribution(entity_id="user_123", process_id="my_agent")

messages = [{"role": "user", "content": "My name is Alice."}]
response = client.chat.completions.create(model="gpt-4o-mini", messages=messages)
messages.append({"role": "assistant", "content": response.choices[0].message.content})

messages.append({"role": "user", "content": "What's my name?"})
response = client.chat.completions.create(model="gpt-4o-mini", messages=messages)
print(response.choices[0].message.content)
```
